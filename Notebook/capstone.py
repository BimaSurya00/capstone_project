# -*- coding: utf-8 -*-
"""Capstone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FRFdxmdbe1Y1zioEs_uCwQqbqE3Z5fa3

## Import Library
"""

import numpy as np
import os
from google.colab import files
import matplotlib.pyplot as plt
from imutils import paths
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from sklearn.model_selection import train_test_split
import cv2

"""## Load Data"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d sanknn/facemask-detection

!unzip facemask-detection.zip -d facemask-dataset

"""## Data Preprocessing"""

train_dir = "/content/facemask-dataset/Facemaskdetection/train"
val_dir = "/content/facemask-dataset/Facemaskdetection/val"

train_datagen = ImageDataGenerator(
    rescale=1 / 255,
    rotation_range=20,
    zoom_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    horizontal_flip=True,
    fill_mode="nearest",
    validation_split=0.2
)


validation_datagen = ImageDataGenerator(
    rescale=1.0 / 255.0)

train_generator = train_datagen.flow_from_directory(train_dir,
                                                    batch_size=32,
                                                    class_mode='categorical',
                                                    target_size=(224, 224))

validation_generator = validation_datagen.flow_from_directory(val_dir,
                                                                batch_size=32,
                                                                class_mode='categorical',
                                                                target_size=(224, 224))

"""## Training and compile"""

pre_trained_model = MobileNetV2(weights="imagenet", include_top=False,
                                input_tensor=Input(shape=(224, 224, 3)))

for layer in pre_trained_model.layers:
    layer.trainable = False

last_output = pre_trained_model.output

x = AveragePooling2D(pool_size=(7, 7))(last_output)
x = Flatten(name="flatten")(x)
x = Dense(128, activation="relu")(x)
x = Dropout(0.2)(x)
x = Dense(2, activation="softmax")(x)

model = Model(pre_trained_model.input, x)

model.summary()

lr=0.0001
epochs=20

optimizer = tf.optimizers.Adam(lr=lr, decay=lr/epochs )
model.compile(optimizer=optimizer,
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_generator, 
                    steps_per_epoch=20,
                    epochs = 20, 
                    validation_steps = 5,
                    validation_data=validation_generator
                    )

"""## Plot Loss and Accuracy"""

plt.style.use("ggplot")
plt.figure(figsize=(10, 5))
plt.plot(np.arange(0, epochs), history.history["loss"], label="training")
plt.plot(np.arange(0, epochs), history.history["val_loss"], label="validation")
plt.title("Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.figure(figsize=(10, 5))
plt.plot(history.history["accuracy"], label="training")
plt.plot(history.history["val_accuracy"], label="validation")
plt.title("Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

"""## Test"""

print(train_generator.class_indices)

from tensorflow.keras.preprocessing import image
uploaded = files.upload()

for fn in uploaded.keys():
 
  path = fn
  img = image.load_img(path, target_size=(224,224))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  output_class = np.argmax(classes)
  print(fn)
  if output_class==0:
    print('with_mask')
  else:
    print('without_mask')

uploaded = files.upload()

for fn in uploaded.keys():
 
  path = fn
  img = image.load_img(path, target_size=(224,224))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  output_class = np.argmax(classes)
  print(fn)
  if output_class==0:
    print('with_mask')
  else:
    print('without_mask')

"""## Save Model"""

model.save('model-facemask.h5')